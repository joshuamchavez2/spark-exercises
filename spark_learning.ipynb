{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7380114",
   "metadata": {},
   "source": [
    "# Purpose of this notebook is to learn Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70f8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca5772d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you Create a new spark session\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b25e22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.19:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ffb42d10ee0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89824c74",
   "metadata": {},
   "source": [
    "### If you want to convert a Pandas Dataframe to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f09294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n group\n",
       "0  0     b\n",
       "1  1     b\n",
       "2  2     c"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(456)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame(\n",
    "    dict(n=np.arange(20), group=np.random.choice(list(\"abc\"), 20))\n",
    ")\n",
    "pandas_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "600a11d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[n: bigint, group: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3bf8c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[n: bigint, group: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f245d9",
   "metadata": {},
   "source": [
    "    Notice that, while we do see the column names, we don't see the data in the dataframe\n",
    "    like we would with a pandas dataframe. This is because spark is lazy, in that it won't\n",
    "    show us values until it has to. For the purposes of looking at the first few rows of\n",
    "    our data, we can use the .show method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbfa7a7",
   "metadata": {},
   "source": [
    "### .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413a0bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  n|group|\n",
      "+---+-----+\n",
      "|  0|    b|\n",
      "|  1|    b|\n",
      "|  2|    c|\n",
      "|  3|    a|\n",
      "|  4|    c|\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782fe1c8",
   "metadata": {},
   "source": [
    "### .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d7cd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, n: string, group: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c60038",
   "metadata": {},
   "source": [
    "    Which, also like pandas, returns another dataframe. \n",
    "    However, since this is a spark dataframe, we have to explicitly show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca3a872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----+\n",
      "|summary|                n|group|\n",
      "+-------+-----------------+-----+\n",
      "|  count|               20|   20|\n",
      "|   mean|              9.5| null|\n",
      "| stddev|5.916079783099616| null|\n",
      "|    min|                0|    a|\n",
      "|    max|               19|    c|\n",
      "+-------+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b7107",
   "metadata": {},
   "source": [
    "### Lets use a more robust dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51b627e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "163a304d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'hwy'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.hwy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4cf18",
   "metadata": {},
   "source": [
    "    While this expression would produce a Series of values from a pandas dataframe,\n",
    "    for a spark dataframe this produces a Column object, which is an object that \n",
    "    represents a vertical slice of a dataframe, but does not contain the data itself.\n",
    "\n",
    "    One way to use our column objects is to use them in combination with the .select\n",
    "    method. .select is very powerful, and lets us specify what data we want to see \n",
    "    in the resulting dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53741291",
   "metadata": {},
   "source": [
    "### .select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c40b6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|hwy|\n",
      "+---+\n",
      "| 29|\n",
      "| 29|\n",
      "| 31|\n",
      "| 30|\n",
      "| 26|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.hwy).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef91e69",
   "metadata": {},
   "source": [
    "### Arithmetic Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc66e881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|hwy|(hwy + 1)|\n",
      "+---+---------+\n",
      "| 29|       30|\n",
      "| 29|       30|\n",
      "| 31|       32|\n",
      "| 30|       31|\n",
      "| 26|       27|\n",
      "+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.hwy, mpg.hwy + 1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f0783",
   "metadata": {},
   "source": [
    "    Our column objects support a numer of operations,\n",
    "    including the arithmetic operators:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f1edd",
   "metadata": {},
   "source": [
    "### .alias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5e937fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+\n",
      "|hwy|highway_mileage|\n",
      "+---+---------------+\n",
      "| 29|             34|\n",
      "| 29|             34|\n",
      "| 31|             36|\n",
      "| 30|             35|\n",
      "| 26|             31|\n",
      "+---+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.hwy, (mpg.hwy + 5).alias(\"highway_mileage\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad31a81",
   "metadata": {},
   "source": [
    "    here I am selecting hwy and hwy + 5\n",
    "    I am also only renaming hwy + 5 with .alias as highway_mileage\n",
    "    finally showing only 5 records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e81d7",
   "metadata": {},
   "source": [
    "### Storing column objects in variables and reference them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3e7f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------+\n",
      "|highway_mileage|highway_mileage_halved|\n",
      "+---------------+----------------------+\n",
      "|             29|                  14.5|\n",
      "|             29|                  14.5|\n",
      "|             31|                  15.5|\n",
      "|             30|                  15.0|\n",
      "|             26|                  13.0|\n",
      "+---------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col1 = mpg.hwy.alias(\"highway_mileage\")\n",
    "col2 = (mpg.hwy / 2).alias(\"highway_mileage_halved\")\n",
    "mpg.select(col1, col2).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb41707",
   "metadata": {},
   "source": [
    "# Other ways to create columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fae454cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ffcc7f",
   "metadata": {},
   "source": [
    "### col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "822a5d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'hwy'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equal to df[\"hwy\"] instead of using df.hwy\n",
    "col(\"hwy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69d8629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-----------+\n",
      "|highway_mileage|city_mileage|avg_mileage|\n",
      "+---------------+------------+-----------+\n",
      "|             29|          18|       23.5|\n",
      "|             29|          21|       25.0|\n",
      "|             31|          20|       25.5|\n",
      "|             30|          21|       25.5|\n",
      "|             26|          16|       21.0|\n",
      "+---------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_column = (col(\"hwy\") + col(\"cty\")) / 2\n",
    "\n",
    "mpg.select(\n",
    "    col(\"hwy\").alias(\"highway_mileage\"),\n",
    "    mpg.cty.alias(\"city_mileage\"),\n",
    "    avg_column.alias(\"avg_mileage\"),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b3781",
   "metadata": {},
   "source": [
    "### expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b83799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------------+-------------------+\n",
      "|hwy|(hwy + 1)|highway_mileage|highway_incremented|\n",
      "+---+---------+---------------+-------------------+\n",
      "| 29|       30|             29|                 30|\n",
      "| 29|       30|             29|                 30|\n",
      "| 31|       32|             31|                 32|\n",
      "| 30|       31|             30|                 31|\n",
      "| 26|       27|             26|                 27|\n",
      "+---+---------+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    expr(\"hwy\"),  # the same as `col`\n",
    "    expr(\"hwy + 1\"),  # an arithmetic expression\n",
    "    expr(\"hwy AS highway_mileage\"),  # using an alias\n",
    "    expr(\"hwy + 1 AS highway_incremented\"),  # a combination of the above\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0369019f",
   "metadata": {},
   "source": [
    "    The expr function is more powerful than col. It does everything\n",
    "    col does and more. expr returns the same type of column object,\n",
    "    but allows us to express manipulations to the column within the\n",
    "    string that defines the column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e3cd8",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e6588",
   "metadata": {},
   "source": [
    "### In order to start using spark SQL, we'll first \"register\" the table with spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "178133bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register table with spark\n",
    "mpg.createOrReplaceTempView(\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "051ecb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hwy: bigint, cty: bigint, avg: double]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "    SELECT hwy, cty, (hwy + cty) / 2 AS avg\n",
    "    FROM mpg\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5cc6f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|hwy|cty| avg|\n",
      "+---+---+----+\n",
      "| 29| 18|23.5|\n",
      "| 29| 21|25.0|\n",
      "| 31| 20|25.5|\n",
      "| 30| 21|25.5|\n",
      "| 26| 16|21.0|\n",
      "+---+---+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "    SELECT hwy, cty, (hwy + cty) / 2 AS avg\n",
    "    FROM mpg\n",
    "\"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12436be",
   "metadata": {},
   "source": [
    "# Type Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35dcf75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('manufacturer', 'string'),\n",
       " ('model', 'string'),\n",
       " ('displ', 'double'),\n",
       " ('year', 'bigint'),\n",
       " ('cyl', 'bigint'),\n",
       " ('trans', 'string'),\n",
       " ('drv', 'string'),\n",
       " ('cty', 'bigint'),\n",
       " ('hwy', 'bigint'),\n",
       " ('fl', 'string'),\n",
       " ('class', 'string')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e52eafc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- displ: double (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- cyl: long (nullable = true)\n",
      " |-- trans: string (nullable = true)\n",
      " |-- drv: string (nullable = true)\n",
      " |-- cty: long (nullable = true)\n",
      " |-- hwy: long (nullable = true)\n",
      " |-- fl: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ef438",
   "metadata": {},
   "source": [
    "### To convert from one type to another, we can use the .cast method on a column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd368a82",
   "metadata": {},
   "source": [
    "### .cast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e6846ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hwy: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.hwy.cast(\"string\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "394620d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hwy', 'string')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.select(mpg.hwy.cast(\"string\")).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91980ff2",
   "metadata": {},
   "source": [
    "## Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b70c839f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|model|model|\n",
      "+-----+-----+\n",
      "|   a4| null|\n",
      "|   a4| null|\n",
      "|   a4| null|\n",
      "|   a4| null|\n",
      "|   a4| null|\n",
      "+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.model, mpg.model.cast(\"int\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea2c15",
   "metadata": {},
   "source": [
    "    Note that if a value is not able to be converted,\n",
    "    it will be replaced with null:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c389c",
   "metadata": {},
   "source": [
    "# Basic Built-in Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d331bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The pyspark avg and mean functions are aliases of eachother\n",
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fbf54a",
   "metadata": {},
   "source": [
    "### sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27411eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------------+--------+--------+\n",
      "|(sum(hwy) / count(hwy) AS average_1)|        average_2|min(hwy)|max(hwy)|\n",
      "+------------------------------------+-----------------+--------+--------+\n",
      "|                   23.44017094017094|23.44017094017094|      12|      44|\n",
      "+------------------------------------+-----------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    sum(mpg.hwy) / count(mpg.hwy).alias(\"average_1\"),\n",
    "    avg(mpg.hwy).alias(\"average_2\"),\n",
    "    min(mpg.hwy),\n",
    "    max(mpg.hwy),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe98a9",
   "metadata": {},
   "source": [
    "### concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35699845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|concat(manufacturer, model)|\n",
      "+---------------------------+\n",
      "|                     audia4|\n",
      "|                     audia4|\n",
      "|                     audia4|\n",
      "|                     audia4|\n",
      "|                     audia4|\n",
      "+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(concat(mpg.manufacturer, mpg.model)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1983b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|manufacturer|\n",
      "+------------+\n",
      "|        audi|\n",
      "|        audi|\n",
      "|        audi|\n",
      "|        audi|\n",
      "|        audi|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.manufacturer).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7008553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|model|\n",
      "+-----+\n",
      "|   a4|\n",
      "|   a4|\n",
      "|   a4|\n",
      "|   a4|\n",
      "|   a4|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.model).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22858214",
   "metadata": {},
   "source": [
    "# lit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151d9e6",
   "metadata": {},
   "source": [
    "    In order to use a string literal as part of our select\n",
    "    we'll need to use the lit function, otherwise spark will\n",
    "    try to resolve our string as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45b69359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "551005f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|concat(cyl,  cylinders)|\n",
      "+-----------------------+\n",
      "|            4 cylinders|\n",
      "|            4 cylinders|\n",
      "|            4 cylinders|\n",
      "|            4 cylinders|\n",
      "|            6 cylinders|\n",
      "+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(concat(mpg.cyl, lit(\" cylinders\"))).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400bb86a",
   "metadata": {},
   "source": [
    "### More pyspark Functions for String Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3fff814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19bd3987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|address                                      |\n",
      "+---------------------------------------------+\n",
      "|600 Navarro St ste 600, San Antonio, TX 78205|\n",
      "|3130 Broadway St, San Antonio, TX 78209      |\n",
      "|303 Pearl Pkwy, San Antonio, TX 78215        |\n",
      "|1255 SW Loop 410, San Antonio, TX 78227      |\n",
      "+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textdf = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"address\": [\n",
    "                \"600 Navarro St ste 600, San Antonio, TX 78205\",\n",
    "                \"3130 Broadway St, San Antonio, TX 78209\",\n",
    "                \"303 Pearl Pkwy, San Antonio, TX 78215\",\n",
    "                \"1255 SW Loop 410, San Antonio, TX 78227\",\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "textdf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8dead1",
   "metadata": {},
   "source": [
    "### regexp_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb08b9c",
   "metadata": {},
   "source": [
    "    The regexp_extract function lets us specify a regular \n",
    "    expression with at least one capture group,\n",
    "    and create a new column based on the contents of a \n",
    "    capture group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "185101af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+---------+------------------+\n",
      "|address                                      |street_no|street            |\n",
      "+---------------------------------------------+---------+------------------+\n",
      "|600 Navarro St ste 600, San Antonio, TX 78205|600      |Navarro St ste 600|\n",
      "|3130 Broadway St, San Antonio, TX 78209      |3130     |Broadway St       |\n",
      "|303 Pearl Pkwy, San Antonio, TX 78215        |303      |Pearl Pkwy        |\n",
      "|1255 SW Loop 410, San Antonio, TX 78227      |1255     |SW Loop 410       |\n",
      "+---------------------------------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textdf.select(\n",
    "    \"address\",\n",
    "    regexp_extract(\"address\", r\"^(\\d+)\", 1).alias(\"street_no\"),\n",
    "    regexp_extract(\"address\", r\"^\\d+\\s([\\w\\s]+?),\", 1).alias(\"street\"),\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f486d3",
   "metadata": {},
   "source": [
    "### regexp_replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f683d",
   "metadata": {},
   "source": [
    "    In the example below, we obtain just the city, \n",
    "    state, and zip code of the address by replacing\n",
    "    everything up to the first comma with an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9827a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+---------------------+\n",
      "|address                                      |city_state_zip       |\n",
      "+---------------------------------------------+---------------------+\n",
      "|600 Navarro St ste 600, San Antonio, TX 78205|San Antonio, TX 78205|\n",
      "|3130 Broadway St, San Antonio, TX 78209      |San Antonio, TX 78209|\n",
      "|303 Pearl Pkwy, San Antonio, TX 78215        |San Antonio, TX 78215|\n",
      "|1255 SW Loop 410, San Antonio, TX 78227      |San Antonio, TX 78227|\n",
      "+---------------------------------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textdf.select(\n",
    "    \"address\",\n",
    "    regexp_replace(\"address\", r\"^.*?,\\s*\", \"\").alias(\"city_state_zip\"),\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb2099c",
   "metadata": {},
   "source": [
    "### .filter and .where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a886ad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+----------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|     class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+----------+\n",
      "|       honda|civic|  1.6|1999|  4|manual(m5)|  f| 28| 33|  r|subcompact|\n",
      "|       honda|civic|  1.6|1999|  4|  auto(l4)|  f| 24| 32|  r|subcompact|\n",
      "|       honda|civic|  1.6|1999|  4|manual(m5)|  f| 25| 32|  r|subcompact|\n",
      "|       honda|civic|  1.6|1999|  4|manual(m5)|  f| 23| 29|  p|subcompact|\n",
      "|       honda|civic|  1.6|1999|  4|  auto(l4)|  f| 24| 32|  r|subcompact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.filter(mpg.cyl == 4).where(mpg[\"class\"] == \"subcompact\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0057ed",
   "metadata": {},
   "source": [
    "# When and Otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b4f0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf498e",
   "metadata": {},
   "source": [
    "### .when()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e62bf9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "|hwy|    mpg_desc|\n",
      "+---+------------+\n",
      "| 29|good_mileage|\n",
      "| 29|good_mileage|\n",
      "| 31|good_mileage|\n",
      "| 30|good_mileage|\n",
      "| 26|good_mileage|\n",
      "| 26|good_mileage|\n",
      "| 27|good_mileage|\n",
      "| 26|good_mileage|\n",
      "| 25|        null|\n",
      "| 28|good_mileage|\n",
      "| 27|good_mileage|\n",
      "| 25|        null|\n",
      "+---+------------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.hwy, when(mpg.hwy > 25, \"good_mileage\").alias(\"mpg_desc\")).show(\n",
    "    12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6556d07",
   "metadata": {},
   "source": [
    "### .otherwise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e93ce5",
   "metadata": {},
   "source": [
    "    Notice below that if the condition we specified is false,\n",
    "    null will be produced. Instead of null, we can specify a\n",
    "    value to use if our condition is false with the .otherwise\n",
    "    method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7698b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "|hwy|    mpg_desc|\n",
      "+---+------------+\n",
      "| 29|good_mileage|\n",
      "| 29|good_mileage|\n",
      "| 31|good_mileage|\n",
      "| 30|good_mileage|\n",
      "| 26|good_mileage|\n",
      "| 26|good_mileage|\n",
      "| 27|good_mileage|\n",
      "| 26|good_mileage|\n",
      "| 25| bad_mileage|\n",
      "| 28|good_mileage|\n",
      "| 27|good_mileage|\n",
      "| 25| bad_mileage|\n",
      "+---+------------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    mpg.hwy,\n",
    "    when(mpg.hwy > 25, \"good_mileage\")\n",
    "    .otherwise(\"bad_mileage\")\n",
    "    .alias(\"mpg_desc\"),\n",
    ").show(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93ec0a",
   "metadata": {},
   "source": [
    "### Multiple .when() statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ec2efae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|displ|engine_size|\n",
      "+-----+-----------+\n",
      "|  1.8|      small|\n",
      "|  1.8|      small|\n",
      "|  2.0|     medium|\n",
      "|  2.0|     medium|\n",
      "|  2.8|     medium|\n",
      "|  2.8|     medium|\n",
      "|  3.1|      large|\n",
      "|  1.8|      small|\n",
      "|  1.8|      small|\n",
      "|  2.0|     medium|\n",
      "+-----+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    mpg.displ,\n",
    "    (\n",
    "        when(mpg.displ < 2, \"small\")\n",
    "        .when(mpg.displ < 3, \"medium\")\n",
    "        .otherwise(\"large\")\n",
    "        .alias(\"engine_size\")\n",
    "    ),\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8963efb4",
   "metadata": {},
   "source": [
    "    Notice here that a car with a displ of 1.8 matches \n",
    "    both conditions we specified, but small is produced \n",
    "    because it is associated with the first matching condition. \n",
    "    For any value between 2 and 3, medium will be produced, \n",
    "    and anything larger than 3 will produce large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc26f8f",
   "metadata": {},
   "source": [
    "# Sorting and Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85f8e287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-----+----+---+----------+---+---+---+---+------+\n",
      "|manufacturer|              model|displ|year|cyl|     trans|drv|cty|hwy| fl| class|\n",
      "+------------+-------------------+-----+----+---+----------+---+---+---+---+------+\n",
      "|       dodge|ram 1500 pickup 4wd|  4.7|2008|  8|manual(m6)|  4|  9| 12|  e|pickup|\n",
      "|       dodge|  dakota pickup 4wd|  4.7|2008|  8|  auto(l5)|  4|  9| 12|  e|pickup|\n",
      "|       dodge|        durango 4wd|  4.7|2008|  8|  auto(l5)|  4|  9| 12|  e|   suv|\n",
      "|        jeep| grand cherokee 4wd|  4.7|2008|  8|  auto(l5)|  4|  9| 12|  e|   suv|\n",
      "|       dodge|ram 1500 pickup 4wd|  4.7|2008|  8|  auto(l5)|  4|  9| 12|  e|pickup|\n",
      "|        jeep| grand cherokee 4wd|  6.1|2008|  8|  auto(l5)|  4| 11| 14|  p|   suv|\n",
      "|   chevrolet|    k1500 tahoe 4wd|  5.3|2008|  8|  auto(l4)|  4| 11| 14|  e|   suv|\n",
      "|  land rover|        range rover|  4.0|1999|  8|  auto(l4)|  4| 11| 15|  p|   suv|\n",
      "+------------+-------------------+-----+----+---+----------+---+---+---+---+------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.sort(mpg.hwy).show(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5b2a7",
   "metadata": {},
   "source": [
    "### Ascending and Descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6138900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e76aa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----+---+----------+---+---+---+---+----------+\n",
      "|manufacturer|     model|displ|year|cyl|     trans|drv|cty|hwy| fl|     class|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+----------+\n",
      "|  volkswagen|     jetta|  1.9|1999|  4|manual(m5)|  f| 33| 44|  d|   compact|\n",
      "|  volkswagen|new beetle|  1.9|1999|  4|manual(m5)|  f| 35| 44|  d|subcompact|\n",
      "|  volkswagen|new beetle|  1.9|1999|  4|  auto(l4)|  f| 29| 41|  d|subcompact|\n",
      "|      toyota|   corolla|  1.8|2008|  4|manual(m5)|  f| 28| 37|  r|   compact|\n",
      "|       honda|     civic|  1.8|2008|  4|  auto(l5)|  f| 25| 36|  r|subcompact|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.sort(mpg.hwy.desc())\n",
    "# is the same as\n",
    "mpg.sort(col(\"hwy\").desc())\n",
    "# is the same as\n",
    "mpg.sort(desc(\"hwy\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd6220",
   "metadata": {},
   "source": [
    "### Sorting by multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af4176e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-----+\n",
      "|manufacturer|             model|displ|year|cyl|     trans|drv|cty|hwy| fl|class|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-----+\n",
      "|      subaru|      forester awd|  2.5|2008|  4|manual(m5)|  4| 20| 27|  r|  suv|\n",
      "|      subaru|      forester awd|  2.5|2008|  4|  auto(l4)|  4| 20| 26|  r|  suv|\n",
      "|      subaru|      forester awd|  2.5|1999|  4|manual(m5)|  4| 18| 25|  r|  suv|\n",
      "|      subaru|      forester awd|  2.5|2008|  4|manual(m5)|  4| 19| 25|  p|  suv|\n",
      "|      subaru|      forester awd|  2.5|1999|  4|  auto(l4)|  4| 18| 24|  r|  suv|\n",
      "|      subaru|      forester awd|  2.5|2008|  4|  auto(l4)|  4| 18| 23|  p|  suv|\n",
      "|      toyota|       4runner 4wd|  2.7|1999|  4|manual(m5)|  4| 15| 20|  r|  suv|\n",
      "|      toyota|       4runner 4wd|  2.7|1999|  4|  auto(l4)|  4| 16| 20|  r|  suv|\n",
      "|        jeep|grand cherokee 4wd|  3.0|2008|  6|  auto(l5)|  4| 17| 22|  d|  suv|\n",
      "|        jeep|grand cherokee 4wd|  4.0|1999|  6|  auto(l4)|  4| 15| 20|  r|  suv|\n",
      "|      toyota|       4runner 4wd|  4.0|2008|  6|  auto(l5)|  4| 16| 20|  r|  suv|\n",
      "|      nissan|    pathfinder 4wd|  4.0|2008|  6|  auto(l5)|  4| 14| 20|  p|  suv|\n",
      "|        ford|      explorer 4wd|  4.0|1999|  6|manual(m5)|  4| 15| 19|  r|  suv|\n",
      "|      toyota|       4runner 4wd|  3.4|1999|  6|  auto(l4)|  4| 15| 19|  r|  suv|\n",
      "|     mercury|   mountaineer 4wd|  4.0|2008|  6|  auto(l5)|  4| 13| 19|  r|  suv|\n",
      "|        ford|      explorer 4wd|  4.0|2008|  6|  auto(l5)|  4| 13| 19|  r|  suv|\n",
      "|        jeep|grand cherokee 4wd|  3.7|2008|  6|  auto(l5)|  4| 15| 19|  r|  suv|\n",
      "|        ford|      explorer 4wd|  4.0|1999|  6|  auto(l5)|  4| 14| 17|  r|  suv|\n",
      "|        ford|      explorer 4wd|  4.0|1999|  6|  auto(l5)|  4| 14| 17|  r|  suv|\n",
      "|      nissan|    pathfinder 4wd|  3.3|1999|  6|  auto(l4)|  4| 14| 17|  r|  suv|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.sort(desc(\"class\"), mpg.cyl.asc(), col(\"hwy\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c40ab",
   "metadata": {},
   "source": [
    "# Grouping and Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e4e5f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x7ffb439de0a0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.groupBy(mpg.cyl)\n",
    "mpg.groupBy(col(\"cyl\"))\n",
    "mpg.groupBy(\"cyl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc9108",
   "metadata": {},
   "source": [
    "    Once the data is grouped, we need to specify an \n",
    "    aggregation. We can use one of the aggregate \n",
    "    functions we imported earlier, alond with a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c3ea975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+\n",
      "|cyl|          avg(cty)|         avg(hwy)|\n",
      "+---+------------------+-----------------+\n",
      "|  6| 16.21518987341772|22.82278481012658|\n",
      "|  8|12.571428571428571|17.62857142857143|\n",
      "|  4|21.012345679012345|28.80246913580247|\n",
      "|  5|              20.5|            28.75|\n",
      "+---+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.groupBy(mpg.cyl).agg(avg(mpg.cty), avg(mpg.hwy)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42e172c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------------+------------------+\n",
      "|cyl|     class|          avg(cty)|          avg(hwy)|\n",
      "+---+----------+------------------+------------------+\n",
      "|  6|    pickup|              14.5|              17.9|\n",
      "|  8|       suv|12.131578947368421|16.789473684210527|\n",
      "|  8|    pickup|              11.8|              15.8|\n",
      "|  8|   midsize|              16.0|              24.0|\n",
      "|  4|   midsize|              20.5|           29.1875|\n",
      "|  8|   2seater|              15.4|              24.8|\n",
      "|  6|   compact|16.923076923076923|25.307692307692307|\n",
      "|  6|   minivan|              15.6|              22.2|\n",
      "|  4|   compact|            21.375|          29.46875|\n",
      "|  6|   midsize|17.782608695652176| 26.26086956521739|\n",
      "|  4|   minivan|              18.0|              24.0|\n",
      "|  6|       suv|              14.5|              18.5|\n",
      "|  6|subcompact|              17.0|24.714285714285715|\n",
      "|  4|subcompact|22.857142857142858| 30.80952380952381|\n",
      "|  8|subcompact|              14.8|              21.6|\n",
      "|  4|       suv|              18.0|             23.75|\n",
      "|  5|   compact|              21.0|              29.0|\n",
      "|  5|subcompact|              20.0|              28.5|\n",
      "|  4|    pickup|              16.0|20.666666666666668|\n",
      "+---+----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.groupBy(\"cyl\", \"class\").agg(avg(mpg.cty), avg(mpg.hwy)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c768c378",
   "metadata": {},
   "source": [
    "### .groupBy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb179e1",
   "metadata": {},
   "source": [
    "    In addition to .groupBy, we can use .rollup,\n",
    "    which will do the same aggregations,\n",
    "    but will also include the overall total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3ae9b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| cyl|count|\n",
      "+----+-----+\n",
      "|null|  234|\n",
      "|   4|   81|\n",
      "|   5|    4|\n",
      "|   6|   79|\n",
      "|   8|   70|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.rollup(\"cyl\").count().sort(\"cyl\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15ff6025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "| cyl|         avg(hwy)|\n",
      "+----+-----------------+\n",
      "|null|23.44017094017094|\n",
      "|   4|28.80246913580247|\n",
      "|   5|            28.75|\n",
      "|   6|22.82278481012658|\n",
      "|   8|17.62857142857143|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.rollup(\"cyl\").agg(expr(\"avg(hwy)\")).sort(\"cyl\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51af6c9",
   "metadata": {},
   "source": [
    "    And in the example above, the null row represents\n",
    "    the overall average highway mileage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c0bf4",
   "metadata": {},
   "source": [
    "# Crosstabs and Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4c351",
   "metadata": {},
   "source": [
    "### .crosstabs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "08b122b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---+---+---+\n",
      "| class_cyl|  4|  5|  6|  8|\n",
      "+----------+---+---+---+---+\n",
      "|   midsize| 16|  0| 23|  2|\n",
      "|subcompact| 21|  2|  7|  5|\n",
      "|   2seater|  0|  0|  0|  5|\n",
      "|    pickup|  3|  0| 10| 20|\n",
      "|   minivan|  1|  0| 10|  0|\n",
      "|       suv|  8|  0| 16| 38|\n",
      "|   compact| 32|  2| 13|  0|\n",
      "+----------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.crosstab(\"class\", \"cyl\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429d25d",
   "metadata": {},
   "source": [
    "### .pivot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3565b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----+------------------+------------------+\n",
      "|     class|                 4|   5|                 6|                 8|\n",
      "+----------+------------------+----+------------------+------------------+\n",
      "|subcompact| 30.80952380952381|28.5|24.714285714285715|              21.6|\n",
      "|   compact|          29.46875|29.0|25.307692307692307|              null|\n",
      "|   minivan|              24.0|null|              22.2|              null|\n",
      "|       suv|             23.75|null|              18.5|16.789473684210527|\n",
      "|   midsize|           29.1875|null| 26.26086956521739|              24.0|\n",
      "|    pickup|20.666666666666668|null|              17.9|              15.8|\n",
      "|   2seater|              null|null|              null|              24.8|\n",
      "+----------+------------------+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.groupby(\"class\").pivot(\"cyl\").mean(\"hwy\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b29703",
   "metadata": {},
   "source": [
    "    More to learn later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fd9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
